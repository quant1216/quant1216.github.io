---
title: "DE01-How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh"
source: https://martinfowler.com/articles/data-monolith-to-mesh.html
date: 2019-10-12 14:26:28
categories: data engineering
---
<h2>How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh(어떻게 단일 데이터 레이크에서 분산된 데이터 매쉬로 넘어갈 것인가)</h2>
Many enterprises are investing in their next generation data lake, with the hope of democratizing data at scale to provide business insights and ultimately make automated intelligent decisions. Data platforms based on the data lake architecture have common failure modes that lead to unfulfilled promises at scale. To address these failure modes we need to shift from the centralized paradigm of a lake, or its predecessor data warehouse. We need to shift to a paradigm that draws from modern distributed architecture: considering domains as the first class concern, applying platform thinking to create self-serve data infrastructure, and treating data as a product.

많은 기업들은 데이터가 사업 크기에 상관없이 비즈니스 인사이트를 제공하고 궁극적으로 자동화된 지능화 결정을 할 수 있기를 희망하며, 그들의 다음 세대 데이터 레이크를 위하여 투자하고 있다. 데이터 레이크 구조에 기반하는 데이터 플랫폼들은 사업 크기에 대응하기 어려운 공통적인 문제점으 가지고 있었다. 이러한 문제점을 해결하기 위해, 우리는 중앙 집중화된 레이크의 페러다임 또는 그 이전의 데이터 웨어하우스로부터 변화할 필요가 있다. 우리는 최신의 분산된 아키텍쳐를 가지는 페러다임으로 변화할 필요가 있다: 도메인을 첫 번째 주제로 고려하기, 셀프 서빙되는 데이터 인프라을 고려한 플랫폼을 적용하기, 그리고 데이터를 프로덕트처럼 대우하기

Becoming a data-driven organization remains one of the top strategic goals of many companies I work with. My clients are well aware of the benefits of becoming intelligently empowered: providing the best customer experience based on data and hyper-personalization; reducing operational costs and time through data-driven optimizations; and giving employees super powers with trend analysis and business intelligence. They have been investing heavily in building enablers such as data and intelligence platforms. Despite increasing effort and investment in building such enabling platforms, the organizations find the results middling.

데이터 기반의 조직이 되어가는 것은 내가 함께 일하는 많은 회사들의 첫 번째 전략 목표이다. 나의 고객들은 지능적인 파워를 갖는 것의 이득을 잘 알고 있다: 데이터와 고도화된 개인화의 기반한 최고의 소비자 경험을 제공하는 것; 그리고 직원들에게 트렌드 분석 그리고 비즈니스 인텔리전폼트와 같은 능력을 주는 것. 그들은 데이터와 인텔리전트 플랫폼과 같은 것들을 만들기 위해 엄청난 투자를 하고 있다. 몇 가능한 플랫폼을 만드는데 드는 노력과 투자가 증가함에도 불구하고, 그 기업들은 그저그런 결과들을 찾는다.

I agree that organizations face a multi-faceted complexity in transforming to become data-driven; migrating from decades of legacy systems, resistance of legacy culture to rely on data, and ever competing business priorities. However what I would like to share with you is an architectural perspective that underpins the failure of many data platform initiatives. I demonstrate how we can adapt and apply the learnings of the past decade in building distributed architectures at scale, to the domain of data; and I will introduce a new enterprise data architecture that I call data mesh.

나는 많은 기업들이 데이터 기반으로 전환하는 것에 대해 다수의 복잡함에 직면하는 것에 동의한다; 수십년간 지속된 이전 시스템에서 이동하는 것, 데이터에 기반한 이전의 문화에 대한 저항, 그리고 사업 우선순위에 대한 경쟁까지. 하지만 내가 여러분과 공유하고 싶은 것은 많은 데이터 플랫폼 초기 모델의 실패에 대한 주장을 뒷받침하기 위한 아키텍쳐적 관점이다. 나는 데이터 도메인을 위한, 사업 크기에 대응할 수 있는 분산된 아키텍쳐를 만드는 것에 대해 지난 기간동안 배운것을 어떻게 우리가 적응하고 적용했는지에 대해 이야기할 것이다; 그리고 나는 data mesh라고 불리 새로운 사업 아키텍쳐를 제안할 것이다.

My ask before reading on is to momentarily suspend the deep assumptions and biases that the current paradigm of traditional data platform architecture has established; Be open to the possibility of moving beyond the monolithic and centralized data lakes to an intentionally distributed data mesh architecture; Embrace the reality of ever present, ubiquitous and distributed nature of data.

이 글을 읽기 전 나의 요구는 들전통적인 데이터 플랫폼 아키텍쳐들이 쌓아왔던 많은 가정과 편견들을 잠시동안 보류하는 것이다; 단일화 그리고 중앙 집중화된 데이터 레이크를 넘어서 의도적으로 분산되는 데이터 매쉬 아키텍쳐로 넘어가는 것에 대해 열린 마음을 가져라; 이미 존재하고, 어느 곳에나 있으며, 분산되어있는 데이터의 본성의 현실성을 받아들여라.

<h2>The current enterprise data platform architecture(현재 기업들의 데이터 플랫폼 아키텍쳐)</h2>

It is centralized, monolithic and domain agnostic aka data lake. Almost every client I work with is either planning or building their 3rd generation data and intelligence platform, while admitting the failures of the past generations:

- The first generation: proprietary enterprise data warehouse and business intelligence platforms; solutions with large price tags that have left companies with equally large amounts of technical debt; Technical debt in thousands of unmaintable ETL jobs, tables and reports that only a small group of specialized people understand, resulting in an under-realized positive impact on the business.
- The second generation: big data ecosystem with a data lake as a silver bullet; complex big data ecosystem and long running batch jobs operated by a central team of hyper-specialized data engineers have created data lake monsters that at best has enabled pockets of R&D analytics; over promised and under realized.

이것은 중앙 집중화, 단일적 그리고 도메인에 집중되어 있다. 일명 데이터 레이라고 한다. 나와 함께 일하는 대부분 고객들은 과거 세대들의 실패 사례를 수용하면서 그들의 3세대 데이터 지식 플랫폼을 계획하거나 만들고 있다.

- 1세대 : 회사의 소유 data warehouse 그리고 business intelligence 플랫폼; 회사에 거대한 기술적 부채를 요구하는 가격 태그가 있는 솔루션; 유지할 수 없는 수천가지의 ETL jobs, 테이블 그리고 특정 그룹만 이해할 수 있는 보고서는 business에 있어서 매우 낮은 성과를 보인다.
- 2세대 : data lake를 소유한 big data 시스템; 복잡한 big data 시스템 그리고 전문 데이터 엔지니어에 의해 작동되는 시간이 오래 걸리는 batch job들은 data lake라는 괴물(R&D 분석을 가능하게 하였지만 과하게 뛰어나며 이해하기 어렵다.)을 만들었다.

The third and current generation data platforms are more or less similar to the previous generation, with a modern twist towards (a) streaming for real-time data availability with architectures such as Kappa, (b) unifying the batch and stream processing for data transformation with frameworks such as Apache Beam, as well as (c) fully embracing cloud based managed services for storage, data pipeline execution engines and machine learning platforms. It is evident that the third generation data platform is addressing some of the gaps of the previous generations such as real-time data analytics, as well as reducing the cost of managing big data infrastructure. However it suffers from many of the underlying characteristics that led to the failures of the previous generations.

3세대 그리고 현재의 데이터 플랫폼은 이전의 세대들과는 다르다. 현대적인 필요성을 추구한다. (a) Kappa와 같은 아키텍쳐를 이용하여 실시간 데이터 사용을 가능하게 한다. (b) Apache Beam과 같은 데이터 변형 과정을 위한 batch와 steram processing을 통합한다. (c) 스토리지를 위한 클라우드 기반의 서비스, 데이터 파이프라인 실행 엔진, 머신러닝 플랫폼을 완전하게 수용한다. 3세대 데이터 플랫폼은 이전 세대들이 할 수 없었던 실시간 데이터 분석, 빅데이터 분석을 관리하는데 필요한 비용 감소를 가능하게 한다. 하지만 3세대 시스템은 이전 세대들이 가져왔던 근본적인 특성들로 인해 고통을 받는다.

<h3>Architectural failure modes(아키텍쳐 실패 사례)</h3>
To unpack the underlying limitations that all generations of data platforms carry, let's look at their architecture and their characteristics. In this writeup I use the domain of internet media streaming business such as Spotify, SoundCloud, Apple iTunes, etc. as the example to clarify some of the concepts.

모든 세대의 데이터 플랫폼이 가졌던 근본적인 제한을 알아보기 위해, 그들의 아키텍처와 특성에 대해 알아보자. 이 글에서 나는 몇 개념을 명확하게 하기 위해 Spotify, SoundCloud, Apple iTunes과 같은 internet media streaming business의 지식을 사용한다.

<h4>Centralized and monolithic(중앙 집중적 그리고 단일적)</h4>
At 30,000 feet the data platform architecture looks like Figure 1 below; a centralized piece of architecture whose goal is to:
- Ingest data from all corners of the enterprise, ranging from operational and transactional systems and domains that run the business, or external data providers that augment the knowledge of the enterprise. For example in a media streaming business, data platform is responsible for ingesting large variety of data: the 'media players performance', how their 'users interact with the players', 'songs they play', 'artists they follow', as well as 'labels and artists' that the business has onboarded, the 'financial transactions' with the artists, and external market research data such as 'customer demographic' information.
- Cleanse, enrich, and transform the source data into trustworthy data that can address the needs of a diverse set of consumers. In our example, one of the transformations turns the click streams of user interaction to meaningful sessions enriched with details of the user. This attempts to reconstruct the journey and behavior of the user into aggregate views.
- Serve the datasets to a variety of consumers with a diverse set of needs. This ranges from analytical consumption to exploring the data looking for insights, machine learning based decision making, to business intelligence reports that summarize the performance of the business. In our media streaming example, the platform can serve near real-time error and quality information about the media players around the globe through distributed log interfaces such as Kafka or serve the static aggregate views of a particular artist's records being played to drive financial payments calculation to the artists and labels.

30,000feet위에서 바라보면(먼 관점에서 바라보면) 데이터 플랫폼 아키텍쳐는 아래의 그림 1과 같이 생겼다; 중앙 집중형 아키텍쳐의 목표는 다음과 같다:
- operational, transactional 시스템 그리고 사업을 진행하는 영역 또는 사업의 지식을 증가시키는 외부의 데이터 제공과 같은 사업의 모든 영역에 데이터를 소화한다. media streaming business를 예로 들면, 데이터 플랫폼은 다양한 종류의 데이터를 소화하는데 책임이 있다: 사업이 소유하고 있는 '크리에이터의 능력', '어떻게 고객이 크리에이터와 소통하는지', '그들이 틀었던 노래들', '그들이 구독하는 크리에이터들', '레이블과 크리에이터들'에 대한 정보, 그리고 '크리에이터들의 경제 활동', '소비자 인구조사 정보'와 같은 외부 시장 조사 데이터까지.
- 다양한 소비자군의 요구를 다룰 수 있도록, 신뢰있는 데이터안의 소스 데이터를 정리, 추가, 변형해라. 예를 들면, 하나의 변형은 유저의 클릭 데이터를 유저의 정보가 추가된 의미있는 세션으로 변형한다. 이것은 유저의 경험과 행동을 집계된 뷰로 다시 만들도록 시도한다. 
- 다양한 필요성에 의해 다양한 유저에게 데이터를 전달해라. 이것은 사업 인사이트를 위한 데이터 탐험의 분석적인 소비, 머신러닝 기반의 의사 결정부터 사업의 성과를 요약한 business intelligence 보고서까지 아우른다. 우리의 미디어 스트리밍 예시를 보면, 이 플랫폼은 가까운 kafka와 같은 분산된 log 인터페이스를 통하여 거의 실시간에 전 세계적인 크리에이터들에 대한 오류와 퀄리티 정보를 전달할 수 있다. 또는 크리에이터와 레이블간의 정산을 위해 특정 크리에이터에 의해 재생된 레코드에 대한 변화가 없을 집계 뷰를 제공할 수 있다.

![](../../figs/02%20data-engineering/01.%20How%20to%20Move%20Beyond%20a%20Monolithic%20Data%20Lake%20to%20a%20Distributed%20Data%20Mesh/fig1.png)

It's an accepted convention that the monolithic data platform hosts and owns the data that logically belong to different domains, e.g. 'play events', 'sales KPIs', 'artists', 'albums', 'labels', 'audio', 'podcasts', 'music events', etc.; data from a large number of disparate domains. While over the last decade we have successfully applied domain driven design and bounded context to our operational systems, we have largely disregarded the domain concepts in a data platform. We have moved away from domain oriented data ownership to a centralized domain agnostic data ownership. We pride ourselves on creating the biggest monolith of them all, the big data platform.
단일 데이터 플랫폼은 다른 도메인에 속하는 모든 데이터에 대해 관리하고 소유헤야 하는 것은 당연한 사항이다. 예를 들어, '플레이 이벤트', '판매 KPIs', '아티스트들', '앨범', '레이블', '오디오', '팟캐스트', '음악 이벤트', etc.; 분리된 수많은 도매인들로부터의 데이터. 지난 10년동안 우리는 우리의 operational 시스템들에 도메인 기반의 디자인과 구분되는 영역들을 성공적으로 적용해왔지만, 우리는 데이터 플랫폼 안에서의 도메인 개념을 매우 무시해왔다. 우리는 도메인 기반의 데이터 소유권으로부터 중앙 집중화된 도메인의 소유권으로 움직여왔다. 우리는 모든 데이터를 다루는 우리의 단일 시스템을 만든 우리에 대해 자랑스러워한다.

![](../../figs/02%20data-engineering/01.%20How%20to%20Move%20Beyond%20a%20Monolithic%20Data%20Lake%20to%20a%20Distributed%20Data%20Mesh/fig2.png)

While this centralized model can work for organizations that have a simpler domain with smaller number of diverse comsumption cases, it fails for enterprises with rich domains, a large number of sources and a diverse set of consumers. There are two pressure points on the architecture and the organizational structure of a centralized data platform that often lead to its failure:

- Ubiquitous data and source proliferation: As more data becomes ubiquitously available, the ability to consume it all and harmonize it in one place under the control of one platform diminishes. Imagine just in the domain of 'customer information', there are an increasing number of sources inside and outside of the boundaries of the organization that provide information about the existing and potential customers. The assumption that we need to ingest and store the data in one place to get value from diverse set of sources is going to constrain our ability to respond to proliferation of data sources. I recognize the need for data users such as data scientists and analysts to process a diverse set of datasets with low overhead, as well as the need to separate the operational systems data usage from the data that is consumed for analytical purposes. But I propose that the existing centralized solution is not the optimal answer for large enterprises with rich domains and continuously added new sources.
- Organizations' innovation agenda and consumer proliferation: Organizations' need for rapid experimentation introduces a larger number of use cases for consumption of the data from the platform. This implies an ever growing number of transformations on the data - aggregates, projections and slices that can satisfy the test and learn cycle of innovation. The long response time to satisfy the data consumer needs has historically been a point of organizational friction and remains to be so in the modern data platform architecture.

While I don't want to give my solution away just yet, I need to clarify that I'm not advocating for a fragmented, siloed domain-oriented data often hidden in the bowels of operational systems; siloed domain data that is hard to discover, make sense of and consume. I am not advocating for multiple fragmented data warehouses that are the results of years of accumulated tech debt. This is a concern that leaders in the industry have voiced. But I argue that the response to these accidental silos of unreachable data is not creating a centralized data platform, with a centralized team who owns and curates the data from all domains. It does not organizationally scale as we have learned and demonstrated above.

중앙 집중화된 모델은 회사에 있어서 더 간단하고 단일한 소비 케이스를 구동할 수 있는 반면에, 이것은 엄청나게 거대한 도메인과 다양한 데이터 소스 다양한 소비자 그룹을 가진 기업들에게는 실패작이었다. 실패를 만들어내는 중앙 집중화된 데이터 플랫폼의 아키텍쳐와 구조들은 2가지 약점이 있다.

- 다양한 소스의 데이터 데이터 소스의 폭발적인 증가: 더 많은 데이터가 다양한 소스에서 이용 가능하게 될수록, 한 곳에서 이 모든 것을 소화하고 이것을 조율하는 능력은 약화된다. 
- 회사의 혁신 방향과 소비자의 갑작스런 증가: 빠른 실험에 대한 기업의 요구들은 플랫폼으로부터의 데이터 사용에 더욱 다양한 use case를 요구한다. 이것은 데이터의 다양한 변환과정을 말한다 - aggregates, projections 그리고 slices들은 테스트와 혁신의 러닝 사이클을 충족할 수 있다. 데이터 소비자의 요구사항을 만족하기 위한 긴 resonse time은 역사적으로 봤을때, 조직적인 마찰의 시발점이 되고, 이는 최신 데이터 아키텍쳐에도 남아있다.

아직 나의 솔루션을 주고 싶지는 않지만, 나는 쪼개지고, 한 곳에 쌓아진, 도메인 기반의 데이터(종종 operational 시스템의 깊은 곳에 숨겨져있는)를 옹호하는 것이 아니라는 것을 명확히 하고 싶다; 발견하거나 이해하고 사용하기 쉽지 않게 쌓여진 도메인 데이터. 나는 기술 부채로 수십년동안 누적되어온 결과물인 쪼개져있는 다수의 데이터 웨어하우스들을 옹호하지 않는다. 이것은 산업의 리더들이 말하는 가장 큰 걱정이다. 그러나 그러한 일시적인 다룰 수 없는 데이터들에 대한 대응은 중앙 집중화된, 모든 도메인으로부터의 데이터를 소유하고 관리하는 중앙 집중화된 팀을 유지하는, 데이터 플랫폼을 만들지 않는 것이라고 말할 수 있다. 이것은 우리가 이전에 말했던 것처럼 조직 단위로 크기를 키워나갈 수 없다.

<h4>Coupled pipeline decomposition(묶인 파이프라인 분리)</h4>

The second failure mode of a traditional data platform architecture is related to how we decompose the architecture. At 10,000 feet zooming into the centralized data platform, what we find is an architectural decomposition around the mechanical functions of ingestion, cleansing, aggregation, serving, etc. Architects and technical leaders in organizations decompose an architecture in response to the growth of the platform. As described in the previous section, the need for on-boarding new sources, or responding to new consumers requires the platform to grow. Architects need to find a way to scale the system by breaking it down to its architectural quanta. An architectural quantum, as described in Building Evolutionary Architectures, is an independently deployable component with high functional cohesion, which includes all the structural elements required for the system to function properly. The motivation behind breaking a system down into its architectural quantum is to create independent teams who can each build and operate an architectural quantum. Parallelize work across these teams to reach higher operational scalability and velocity.

옛날 데이터 플랫폼 아키텍쳐의 두 번째 실패 사례는 우리가 아키텍쳐를 어떻게 분리하는가와 관련이 있다. 10,000 feet(조금 더 가까이)에서 중앙 집중화된 데이터 플랫폼을 보면, 우리가 찾은 것은 데이터 수집, 정제, 집계, 전달과 같은 기계적인 기능에 따르는 아키텍쳐적인 분리이다. 조직의 아키텍트들 그리고 기술 리더들은 플랫폼의 성장에 따라 아키텍쳐를 분리한다. 이전 세션에서도 말했지만, 새로운 소스에 대한 온보딩 또는 새로운 소비자에 대한 반응에 대한 필요성은 플랫폼이 커지게 만들었다. 아키텍쳐들은 이것의 아키텍쳐적인 단위들을 쪼갬으로써 시스템을 키울 수 있는 방법을 찾아야 했다. [Building Evolutionary Architectures]에서 명시된 아키텍쳐적인 단위는 이 시스템이 적절히 동작하게 하기 위해 요구되는 모든 구조적인 소단위들의 함수적인 결합성과 함께 독립적으로 배포될 수 있는 단위이다. 아키텍쳐적인 단위들을 나누는 것을 넘어서, 각자 아키텍쳐적인 단위를 만들고 동작시키는 독립적인 팀을 만드는 것이다. 더 높은 시스템 상의 확장성과 속도를 이루기 위해서 팀 사이의 작업들을 병렬화해라.

Given the influence of previous generations of data platforms' architecture, architects decompose the data platform to a pipeline of data processing stages. A pipeline that at a very high level implements a functional cohesion around the technical implementation of processing data; i.e. capabilities of ingestion, preparation, aggregation, serving, etc.

이전 세대의 데이터 플랫폼 아키텍쳐의 영향이 있을 때, 아키텍트들은 데이터 플랫폼을 데이터 프로세싱의 과정에 따라 분리한다. 하나의 파이프라인은 매우 높은 수준에서, 데이터를 프로세싱하는 기술적인 구동 사이에 존재하는 기능적 결합을 이용한다; 즉. 수집, 준비, 집계, 전달의 능력.

![](../../figs/02%20data-engineering/01.%20How%20to%20Move%20Beyond%20a%20Monolithic%20Data%20Lake%20to%20a%20Distributed%20Data%20Mesh/fig3.png)

Though this model provides some level of scale, by assigning teams to different stages of the pipeline, it has an inherent limitation that slows the delivery of features. It has high coupling between the stages of the pipeline to deliver an independent feature or value. It's decomposed orthogonally to the axis of change.

비록 이런 모델은 다팀 단위로 파이프라인의 다른 부분에 할당함으로써 일정 레벨의 확장성을 제공하지만, 이것은 데이터 전달을 느리게 만든다는 태생적 한계가 있다. 이것은 독립적인 특성 또는 가치를 전달하기 위한 파이프라인의 스테이지간의 높은 결합성을 가진다. 이것은 변화에 대해 직교적으로(관련 없는 방향으로) 분리된다.

Let's look at our media streaming example. Internet media streaming platforms have a strong domain construct around the type of media that they offer. They often start their services with 'songs' and 'albums', and then extend to 'music events', 'podcasts', 'radio shows', 'movies', etc. Enabling a single new feature, such as visibility to the 'podcasts play rate', requires a change in all components of the pipeline. Teams must introduce new ingestion services, new cleansing and preparation as well as aggregates for viewing podcast play rates. This requires synchronization across implementation of different components and release management across teams. Many data platforms provide generic and configuration-based ingestion services that can cope with extensions such as adding new sources easily or modifying the existing sources to minimize the overhead of introducing new sources. However this does not remove an end to end dependency management of introducing new datasets from the consumer point of view. Though on paper, the pipeline architecture might appear as if we have achieved an architectural quantum of a pipeline stage, in practice the whole pipeline i.e. the monolithic platform, is the smallest unit that must change to cater for a new functionality: unlocking a new dataset and making it available for new or existing consumption. This limits our ability to achieve higher velocity and scale in response to new consumers or sources of the data.

우리의 미디어 스트리밍 예시를 보자. 인터넷 미디어 스트리밍 플랫폼들은 그들이 제공하는 다양한 타입의 미디어들 간의 강력한 도메인 구조체를 가지고 있다. 그들은 자주 그들의 서비스를 '노래' 그리고 '앨범'과 함께 그들의 서비스를 시작하고, '음악 이벤트', '팟케스트', '라디오 쇼', '영화'와 같은 것으로 확장해나간다. '팟캐스트 재생률'과 같은 하나의 새로운 기능을 가능하게 하는 것은 파이프라인 내의 모든 단위의 변화를 요구한다. 팀들은 새로운 데이터 수집, 정제, 준비, 집계 서비스를 만들어야 한다. 이것은 다른 구성 단위간의 동기화와 팀을 넘나드는 배포 관리를 요구한다. 많은 데이터 플랫폼은 새로운 소스를 도입하는데 쓰는 에너지를 최소화하면서 새로운 소스를 쉽게 추가하고, 존재하는 소스를 수정하는 확장을 다루기 위한, 일반적이고 config 기반의 수집 서비스를 제공한다. 하지만 이것은 소비자의 관점에서 새로운 데이터셋이 추가되는 것에 대해 end2end의 의존성 관리를 제거하지 못 한다. 비록 이 글에서는 파이프라인 아키텍쳐가 파이프라인 단계를 이용하여 구조적 단위를 이룰 수 있는 것처럼 보이지만, 실제로 단일 플랫폼과 같은 전체 파이프라인은 새로운 기능을 위해 변화하고 주어져야할 가장 작은 유닛이다: 새로운 데이터를 열고, 새로운 또는 이전의 소비들도 이용 가능하도록 만드는 것. 이것은 데이터의 새로운 소비체와 소스를 다루기 위해 더 높은 속도와 크기를 가지고 싶은 우리의 능력을 제한한다.  

![](../../figs/02%20data-engineering/01.%20How%20to%20Move%20Beyond%20a%20Monolithic%20Data%20Lake%20to%20a%20Distributed%20Data%20Mesh/fig4.png)

<h4>Siloed and hyper-specialized ownership(한 곳에 모여지고 전문가들에 의한 소유권)</h4>
